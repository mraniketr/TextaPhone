{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pickle-mixin\n",
      "  Downloading pickle-mixin-1.0.2.tar.gz (5.1 kB)\n",
      "Installing collected packages: pickle-mixin\n",
      "    Running setup.py install for pickle-mixin: started\n",
      "    Running setup.py install for pickle-mixin: finished with status 'done'\n",
      "Successfully installed pickle-mixin-1.0.2\n"
     ]
    }
   ],
   "source": [
    "!pip install pickle-mixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('text_emotion.csv')\n",
    "data = data.drop('author', axis=1)\n",
    "\n",
    "\n",
    "data = data.drop(data[data.sentiment == 'anger'].index)\n",
    "data = data.drop(data[data.sentiment == 'boredom'].index)\n",
    "data = data.drop(data[data.sentiment == 'enthusiasm'].index)\n",
    "data = data.drop(data[data.sentiment == 'empty'].index)\n",
    "data = data.drop(data[data.sentiment == 'fun'].index)\n",
    "data = data.drop(data[data.sentiment == 'relief'].index)\n",
    "data = data.drop(data[data.sentiment == 'surprise'].index)\n",
    "data = data.drop(data[data.sentiment == 'love'].index)\n",
    "data = data.drop(data[data.sentiment == 'hate'].index)\n",
    "data = data.drop(data[data.sentiment == 'worry'].index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-0.22.2.post1-cp36-cp36m-win32.whl (5.7 MB)\n",
      "Collecting joblib>=0.11\n",
      "  Downloading joblib-0.14.1-py2.py3-none-any.whl (294 kB)\n",
      "Requirement already satisfied: scipy>=0.17.0 in c:\\users\\busin\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages (from scikit-learn) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.11.0 in c:\\users\\busin\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages (from scikit-learn) (1.18.2)\n",
      "Installing collected packages: joblib, scikit-learn\n",
      "Successfully installed joblib-0.14.1 scikit-learn-0.22.2.post1\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\busin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\busin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "data['content'] = data['content'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "data['content'] = data['content'].str.replace('[^\\w\\s]',' ')\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "data['content'] = data['content'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "\n",
    "nltk.download('wordnet')\n",
    "from textblob import Word\n",
    "data['content'] = data['content'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\n",
    "\n",
    "import re\n",
    "def de_repeat(text):\n",
    "    pattern = re.compile(r\"(.)\\1{2,}\")\n",
    "    return pattern.sub(r\"\\1\\1\", text)\n",
    "#%%\n",
    "data['content'] = data['content'].apply(lambda x: \" \".join(de_repeat(x) for x in x.split()))\n",
    "\n",
    "freq = pd.Series(' '.join(data['content']).split()).value_counts()[-19000:]\n",
    "\n",
    "freq = list(freq.index)\n",
    "data['content'] = data['content'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq))\n",
    "\n",
    "from sklearn import preprocessing\n",
    "lbl_enc = preprocessing.LabelEncoder()\n",
    "y = lbl_enc.fit_transform(data.sentiment.values)\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(data.content.values, y, stratify=y, random_state=42, test_size=0.1, shuffle=True)\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer(analyzer='word')\n",
    "count_vect.fit(data['content'])\n",
    "    X_train_count =  count_vect.transform(X_train)\n",
    "X_val_count =  count_vect.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lsvm using count vectors accuracy 0.594111461619348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\busin\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log reg count vectors accuracy 0.5977917981072555\n",
      "SVM with count vectors accuracy 0.5888538380651945\n",
      "Knn with count vectors accuracy 0.5031545741324921\n"
     ]
    }
   ],
   "source": [
    " from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Model 2: Linear SVM\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "lsvm = SGDClassifier(alpha=0.001, random_state=5, max_iter=15, tol=None)\n",
    "lsvm.fit(X_train_count, y_train)\n",
    "y_pred = lsvm.predict(X_val_count)\n",
    "print('lsvm using count vectors accuracy %s' % accuracy_score(y_pred, y_val))\n",
    "\n",
    "# Model 3: Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression(C=1)\n",
    "logreg.fit(X_train_count, y_train)\n",
    "y_pred = logreg.predict(X_val_count)\n",
    "print('log reg count vectors accuracy %s' % accuracy_score(y_pred, y_val))\n",
    "\n",
    "from sklearn.svm import SVC \n",
    "svm_model_linear = SVC(kernel = 'linear', C = 1).fit(X_train_count, y_train) \n",
    "y_pred = svm_model_linear.predict(X_val_count)\n",
    "print('SVM with count vectors accuracy %s' % accuracy_score(y_pred, y_val))\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "knn = KNeighborsClassifier(n_neighbors = 7).fit(X_train_count, y_train) \n",
    "y_pred = knn.predict(X_val_count)  \n",
    "print('Knn with count vectors accuracy %s' % accuracy_score(y_pred, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 2 1 2 2 2]\n",
      "Happy\n",
      "Happy\n",
      "Happy\n",
      "Sad\n",
      "Neutral\n",
      "Sad\n",
      "Sad\n",
      "Sad\n"
     ]
    }
   ],
   "source": [
    "tweets = pd.DataFrame(['I am very happy today! The atmosphere looks cheerful',\n",
    "'Things are looking great. It was such a good day',\n",
    "'Success is right around the corner. Lets celebrate this victory',\n",
    "'Martha was angry, certainly at the perpetrator but also at the Warwick police for not summarily arresting the man and rescuing the boy.',\n",
    "'Now this is my worst, okay? But I am gonna get better.',\n",
    "'I am tired, boss. Tired of being on the road, lonely as a sparrow in the rain. I am tired of all the pain I feel',\n",
    "'This is quite depressing. I am filled with sorrow',\n",
    "'His death broke my heart. It was a sad day'])\n",
    "# Doing some preprocessing on these tweets as done before\n",
    "tweets[0] = tweets[0].str.replace('[^\\w\\s]',' ')\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "tweets[0] = tweets[0].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "from textblob import Word\n",
    "tweets[0] = tweets[0].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\n",
    "# Extracting Count Vectors feature from our tweets\n",
    "tweet_count = count_vect.transform(tweets[0])\n",
    "#Predicting the emotion of the tweet using our already trained linear SVM\n",
    "tweet_pred = logreg.predict(tweet_count)\n",
    "\n",
    "print(tweet_pred)\n",
    "for i in range(0,len(tweet_pred)):\n",
    "  if tweet_pred[i]==0:\n",
    "    print(\"Happy\")\n",
    "  elif tweet_pred[i]==1:\n",
    "    print(\"Neutral\")\n",
    "  else:\n",
    "    print(\"Sad\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
